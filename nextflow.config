/*
 * -------------------------------------------------
 *  Pipeline config
 * -------------------------------------------------
 */

// Global default params
params {

    // trim
    save_trimmed               = true
    
    // Differential expression and functional enrichment
    cont_tabl                  = false
    p_thresh                   = 0.05
    l2fc_thresh                = 1

    // Options: Other
    help                       = false
    name                       = false   // optional name for the pipeline run
    outdir                     = './results'
    cachedir                   = './'

    // Max resource options
    // Defaults only, expecting to be overwritten
    max_memory                 = '64.GB'
    max_cpus                   = 24
    max_time                   = '10.h'
}


profiles {
    conda {
        conda.enabled          = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
        conda.createTimeout = '2 h'
        conda.createOptions = '-c bioconda -c conda-forge'
    }

}

// Include configs
includeConfig "conf/base.config"


// Export these variables to prevent local Python/R libraries from conflicting with those in the container
env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
}

def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.outdir}/pipeline_info/pipeline_dag_${trace_timestamp}.html"
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
